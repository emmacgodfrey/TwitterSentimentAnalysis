---
title: "Initial EDA"
author: "Emma Godfrey"
date: "11/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(devtools)
library(httpuv)
library(twitteR)
library(tidyverse)
library(tidytext)

library("quanteda")
library("stopwords")
library("tm")
library("wordcloud")
library("SnowballC")
library("RColorBrewer")
library("RCurl")
library("XML")
library("textdata")
library("udpipe")
library("lattice")
library("ggpubr")
library("remotes")
install_github("ropensci/rtweet")
library("rtweet")
library("httpuv")
```

```{r}

token <- setup_twitter_oauth(
  consumer_key = "BiJOj8WjsMpy4gWstvt3M5Xgj", 
  consumer_secret = "4YnjjUETDZf7LZZccUef8WIUr5e1s9MqnCkb2rTo9Mjz4yYXVO",
  access_token = "1330648074885107712-zysJcaWh6dNvFW29LI4rlL3ODcShyH",
  access_secret = "QI4ABwszLDZgmNWyVeTUuRdPiXiHPZyKfCi2xAqIOmq60"
)

tw.harris = searchTwitter('Kamala Harris', n = 1e4, since = '2019-11-08', retryOnRateLimit = 1e4)
d.harris = twListToDF(tw.harris)

# clean data
# change all text to lower case
d.harris$text <- tolower(d.harris$text)
# delete usernames
d.harris$text <- gsub("@\\w+", "", d.harris$text)
# delete punctuation
d.harris$text <- gsub("[[:punct:]]", "", d.harris$text)
# remove links 
d.harris$text <- gsub("http\\w+", "", d.harris$text)

# tokenize tweets
tweet_words_harris <- d.harris %>% select(id, text) %>% unnest_tokens(word,text)

tweet_words_harris %>% count(word, sort = T) %>% slice(1:20) %>% 
  ggplot(aes(x=reorder(word, n, function(n) -n), y=n)) + geom_bar(stat="identity") +theme(axis.text.x = element_text(angle = 60, hjust = 1)) + xlab("") 

my_stop_words_harris <- stop_words %>% select(-lexicon) %>% bind_rows(data.frame(word = c(stopwords(), "kamalaharris","https","t.co","rt", "joebiden", "biden", "kamala", "harris", "a", "the", "to", "and", "in", "you", "of", "is", "i","de", "tweet", "que", "diner", "via","level", "today", "joe", "les", "kamalaharrisvp", "video", "usa", "per", "las", "dinner", "voting", "come", "said", "one", "tonight")))

tweet_words_interesting_harris <- tweet_words_harris %>% anti_join(my_stop_words_harris)

#model <- udpipe_download_model(language = "english")

udmodel_english <- udpipe_load_model(file = '/Users/emmagodfrey/GitRepos/airbnbNY/english-ewt-ud-2.5-191206.udpipe')
s <- udpipe_annotate(udmodel_english, tweet_words_interesting_harris$word)
df.harris <- data.frame(s)

stats.harris <- subset(df.harris, upos %in% c("ADJ"))
stats.harris <- txt_freq(stats.harris$token)
stats.harris$key <- factor(stats.harris$key, levels = rev(stats.harris$key))
barchart(key ~ freq, data = head(stats.harris, 20), col = "cadetblue", 
         main = "Most occurring adjectives", xlab = "Freq")
clean.adj.harris <- stats.harris %>% 
  filter(!(key %in% c("reagan","joebidenpresidentelect", "ead", "ue", "est", "sullivan", "slate", "public", "vpelect", "elect", "key", "necessar", "certific", "vicepresidentelect", "une")))

barchart(key ~ freq, data = head(clean.adj.harris, 30), col = "cadetblue", 
         main = "Most occurring adjectives", xlab = "Freq")


bing_lex <- get_sentiments("nrc")
clean.adj.harris$key <- as.character(clean.adj.harris$key)
sent.adj.harris <- inner_join(clean.adj.harris,bing_lex, by=c("key"= "word"))

pie.words <- sent.adj.harris %>% 
  group_by(sentiment) %>% 
  tally %>%
  arrange(desc(n))

ggpie(pie.words, "n", label = "sentiment", fill = "sentiment", color = "white", palette ="spectral")

rstats <- search_tweets("rstats", n=100, type = "recent", include_rts = FALSE)
```


```{r}
tw.obama = searchTwitter('barack obama', n = 1e4, since = '2019-11-08', retryOnRateLimit = 1e4)
d.obama = twListToDF(tw.obama)
```

```{r}
# change all text to lower case
d.obama$text <- tolower(d.obama$text)
# delete usernames
d.obama$text <- gsub("@\\w+", "", d.obama$text)
# delete punctuation
d.obama$text <- gsub("[[:punct:]]", "", d.obama$text)
# remove links 
d.obama$text <- gsub("http\\w+", "", d.obama$text)

# tokenize tweets
tweet_words_obama <- d.obama %>% select(id, text) %>% unnest_tokens(word,text)

my_stop_words_obama <- stop_words %>% select(-lexicon) %>% bind_rows(data.frame(word = c(stopwords(), "kamalaharris","https","t.co","rt", "joebiden", "biden", "kamala", "harris", "a", "the", "to", "and", "in", "you", "of", "is", "i","de", "tweet", "que", "diner", "via","level", "today", "joe", "les", "kamalaharrisvp", "video", "usa", "per", "las", "dinner", "voting", "come", "said", "one", "tonight", "obama", "barack", "michelle", "obamas")))

tweet_words_interesting_obama <- tweet_words_obama %>% anti_join(my_stop_words_obama)

udmodel_english <- udpipe_load_model(file = '/Users/emmagodfrey/GitRepos/airbnbNY/english-ewt-ud-2.5-191206.udpipe')
s.obama <- udpipe_annotate(udmodel_english, tweet_words_interesting_obama$word)
pos.obama <- data.frame(s.obama)

stats.obama <- subset(pos.obama, upos %in% c("ADJ"))
stats.obama <- txt_freq(stats.obama$token)
stats.obama$key <- factor(stats.obama$key, levels = rev(stats.obama$key))
barchart(key ~ freq, data = head(stats.obama, 20), col = "cadetblue", 
         main = "Most occurring adjectives", xlab = "Freq")
clean.adj.obama <- stats.obama %>% 
  filter(!(key %in% c("national", "dan", "fluffy", "mini", "tellal", "une", "max", "main", "lengthy", "opponent", "sullivan", "biggest", "dan", "opponent")))

barchart(key ~ freq, data = head(clean.adj.obama, 25), col = "cadetblue", 
         main = "Most occurring adjectives", xlab = "Freq")

bing_lex <- get_sentiments("nrc")
clean.adj.obama$key <- as.character(clean.adj.obama$key)
sent.adj.obama <- inner_join(clean.adj.obama,bing_lex, by=c("key"= "word"))

sent.adj.obama %>% group_by(sentiment) %>% count() %>% arrange(desc(n))
```

